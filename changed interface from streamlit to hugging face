import os
import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages import AIMessage, HumanMessage
from langchain_community.llms import HuggingFaceEndpoint
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

load_dotenv()  ## Load environment variables from .env file
api_token = os.getenv("API-token")

repo_id = "mistralai/Mixtral-8x7B-Instruct-v0.1"
task = "text-generation"

st.set_page_config(page_title="Ask-emily",page_icon= "üåç")
st.title("Ask-emily")


template = """
You are Emily, a travel assistant specialized in RV and camping trips. Answer user questions based on the details provided. Make sure to ask for necessary details if they are missing (e.g., destination, dates, RV specifications).
Chat history:
{chat_history}
User question:
{user_question}
Your response:
"""

prompt = ChatPromptTemplate.from_template(template)

# Function to get a response from the model
def get_response(user_query, chat_history):
    # Initialize the Hugging Face Endpoint
    llm = HuggingFaceEndpoint(
        huggingfacehub_api_token=api_token,
        repo_id=repo_id,
        task=task
    )
    limited_chat_history = chat_history[-5:]
    
    chain = prompt | llm | StrOutputParser()

    response = chain.invoke({
        "chat_history": chat_history,
        "user_question": user_query,
    })

    return response

if "chat_history" not in st.session_state:
    st.session_state.chat_history = [
        AIMessage(content="Hello, I am Emily, How can I help you?"),
    ]

# Display chat history
for message in st.session_state.chat_history:
    if isinstance(message, AIMessage):
        with st.chat_message("AI"):
            st.write(message.content)
    elif isinstance(message, HumanMessage):
        with st.chat_message("Human"):
            st.write(message.content)

# User input
user_query = st.chat_input("Type your message here...")
if user_query is not None and user_query != "":
    st.session_state.chat_history.append(HumanMessage(content=user_query))

    with st.chat_message("Human"):
        st.markdown(user_query)

    response = get_response(user_query, st.session_state.chat_history)
    # Clean up the response by removing any unwanted prefixes
    response = response.split("response:")[-1].strip()


    with st.chat_message("AI"):
        st.write(response)

    st.session_state.chat_history.append(AIMessage(content=response))
